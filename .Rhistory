geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
modelo_svm <- svm(diabetes ~ ., data = data, kernel = "linear")
data_test <- data[1:100,]
# Fazendo previsões
previsoes_contínuas <- predict(modelo_svm, data_test, decision.values = TRUE)
# Supondo que 'seu_dataframe' é o seu DataFrame
# 'var_x', 'var_y' e 'var_dummy' são os nomes das suas variáveis
ggplot(data, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
matriz_confusao <- table(data_test$diabetes, previsoes_binarias)
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
matriz_confusao <- table(data_test$diabetes, previsoes_binarias)
print(matriz_confusao)
data_test
data
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret
)
p_loaded()
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret
)
p_loaded()
dados <- read.csv("BankChurners.csv")
# excluir as ultimas duas colunas para ocultar o resultado anterior do projeto
dados <- dados[ ,1:21]
#varificar se há alguma linha repetida
anyDuplicated(dados)
ExpData(dados,type=1)
ExpData(dados,type=2)
str(dados)
plot_intro(dados)
## rodar: unique(dados$VARIAVEL) para perceber a ordem e nomes dos labels
#ajuste variável género
dados$gender_cod <- as.numeric(dados$Gender == "F")
levels(dados$gender_cod) <- c("M", "F")
table(dados$Gender, dados$gender_cod)
#ajuste variável nível de educação
dados$education_cod <- as.numeric(factor(dados$Education_Level, levels = unique(dados$Education_Level)))
levels(dados$education_cod) <- c("High School","Graduate","Uneducated","Unknown","College","Post-Graduate","Doctorate")
table(dados$Education_Level, dados$education_cod)
#ajuste variável flag de atrito
dados$flag <- as.numeric(dados$Attrition_Flag == "Existing Customer")
levels(dados$gender_cod) <- c("Existing Customer", "Attrited Customer")
table(dados$Attrition_Flag, dados$flag)
# ajuste variável estado civil
dados$marital_cod <- as.numeric(factor(dados$Marital_Status, levels = unique(dados$Marital_Status)))
levels(dados$marital_cod) <- c("Married","Single","Unknown","Divorced")
table(dados$Marital_Status, dados$marital_cod)
# ajuste variável nivel de renda
dados$income_cod <- as.numeric(factor(dados$Income_Category, levels = unique(dados$Income_Category)))
levels(dados$income_cod) <- c("$60K - $80K","Less than $40K","$80K - $120K",  "$40K - $60K",
"$120K +","Unknown")
table(dados$Income_Category, dados$income_cod)
# ajuste variável tipo de cartão
dados$card_cod <- as.numeric(factor(dados$Card_Category, levels = unique(dados$Card_Category)))
levels(dados$card_cod) <- c("Blue", "Gold", "Silver", "Platinum")
table(dados$Card_Category, dados$card_cod)
## eliminar variáveis caracteres do DF
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$Attrition_Flag, p = 0.7, list = FALSE)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$flag, p = 0.7, list = FALSE)
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
ggplot(conjunto_treinamento, aes(x = Total_Trans_Amt, y = flag, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
View(conjunto_treinamento)
colnames(dados)
ggplot(conjunto_treinamento, aes(x = Months_Inactive_12_mon, y = flag, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
plot(dados$Attrition_Flag,dados$Months_Inactive_12_mon)
sum(dados$Months_Inactive_12_mon)
sumary(dados$Months_Inactive_12_mon)
summary(dados$Months_Inactive_12_mon)
plot(dados$flag,dados$Months_Inactive_12_mon)
ggplot(conjunto_treinamento, aes(x = Months_Inactive_12_mon, y = flag, color = factor(flag))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
ggplot(conjunto_treinamento, aes(x = Months_Inactive_12_mon, y = flag, color = factor(flag))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
colnames(dados)
ggplot(conjunto_treinamento, aes(x = Total_Ct_Chng_Q4_Q1, y = flag, color = factor(flag))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
ggplot(conjunto_treinamento, aes(x = Total_Ct_Chng_Q4_Q1, y = flag, color = factor(flag))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
ggplot(conjunto_treinamento, aes(x = Total_Ct_Chng_Q4_Q1, y = Months_Inactive_12_mon, color = factor(flag))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "flag") +
theme_minimal()
modelo_svm <- svm(flag ~ Total_Ct_Chng_Q4_Q1 + Months_Inactive_12_mon, data = conjunto_treinamento, kernel = "linear")
# Fazer previsões
previsoes <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
previsoes
plot_density(previsoes)
print(previsoes)
summary(previsoes)
previsoes <- predict(modelo_svm, conjunto_teste)
summary(previsoes)
View(modelo_svm)
colnames(dados)
modelo_svm <- svm(flag ~ Total_Ct_Chng_Q4_Q1 + Months_Inactive_12_mon + Total_Amt_Chng_Q4_Q1, data = conjunto_treinamento, kernel = "linear")
# Fazer previsões
previsoes <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
# Criar um modelo Naive Bayes
modelo_svm <- svm(flag ~ ., data = conjunto_treinamento, kernel = "linear")
# Fazer previsões
previsoes <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
modelo_svm <- svm(flag ~ ., data = conjunto_treinamento, kernel = "linear")
ls(modelo_svm)
rm(modelo_svm)
# Criar um modelo Naive Bayes
modelo_svm <- svm(flag ~ ., data = conjunto_treinamento, kernel = "linear")
rm(previsoes)
# Criar um modelo Naive Bayes
modelo_svm <- svm(flag ~ ., data = conjunto_treinamento, kernel = "linear")
# Fazer previsões
previsoes <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
library(readr)
data <- read_csv("C:/Users/linar/OneDrive - Universidade Europeia/Naive-Bayes-Classification-Data.csv")
View(data)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(data$diabetes, p = 0.7, list = FALSE)
conjunto_treinamento <- data[index, ]
conjunto_teste <- data[-index, ]
ggplot(data, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
modelo_svm <- svm(diabetes ~ ., data = data, kernel = "linear")
# Fazendo previsões
previsoes_contínuas <- predict(modelo_svm, data_test, decision.values = TRUE)
# Fazendo previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
hist(previsoes_contínuas)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
matriz_confusao <- table(data_test$diabetes, previsoes_binarias)
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
Hmisc,
stargazer,
visdat,
rmarkdown,
knitr,
GGally,
summarytools,
extremevalues,
DataExplorer,
gplots,
ggplot2,
SmartEDA,
kableExtra,
e1071,
caret
)
p_loaded()
dados <- read.csv("DiabetesData.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
ExpData(dados,type=1)
ExpData(dados,type=2)
str(dados)
plot_intro(dados)
ggplot(dados, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
ggplot(dados, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
```{r}
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
ggplot(dados, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = data, kernel = "linear")
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "linear")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "sigmoid")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "polynomial")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "radial basis")
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "radial")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "linear")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(error = FALSE)
options(repos = "https://cran.rstudio.com")
rm(list = ls())
if(!require(pacman)) install.packages("pacman")
library(pacman)
pacman::p_load(tidyverse,
rmarkdown,
knitr,
GGally,
DataExplorer,
gplots,
SmartEDA,
e1071,
caret
)
p_loaded()
dados <- read.csv("DiabetesData.csv")
#varificar se há alguma linha repetida
anyDuplicated(dados)
ExpData(dados,type=1)
ExpData(dados,type=2)
str(dados)
plot_intro(dados)
ggplot(dados, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Defina a semente para reproduzibilidade
set.seed(123)
# define a proporção de dados que será usada para treinamento (por exemplo, 0.7 para 70%)
index <- createDataPartition(dados$diabetes, p = 0.7, list = FALSE)
# Crie conjuntos de treinamento e teste com base nos índices
conjunto_treinamento <- dados[index, ]
conjunto_teste <- dados[-index, ]
#validação do Hiperplano na base de treinamento
ggplot(conjunto_treinamento, aes(x = bloodpressure, y = glucose, color = factor(diabetes))) +
geom_point() +
scale_color_manual(values = c("0" = "blue", "1" = "red")) +
labs(color = "diabetes") +
theme_minimal()
# Criar um modelo Naive Bayes
modelo_svm <- svm(diabetes ~ ., data = dados, kernel = "linear")
# Fazer previsões
previsoes_contínuas <- predict(modelo_svm, conjunto_teste, decision.values = TRUE)
limiar <- 0.5  # Escolha um limiar adequado
previsoes_binarias <- ifelse(previsoes_contínuas > limiar, 1, 0)
# Supondo que 'verdadeiro' são os rótulos reais e 'previsoes' são as previsões do modelo
matriz_confusao <- table(conjunto_teste$diabetes, previsoes_binarias)
print(matriz_confusao)
acuracia <- round(sum(diag(matriz_confusao)) / sum(matriz_confusao),3)
precisao <- round(matriz_confusao[1, 1] / sum(matriz_confusao[, 1]),3)
sensibilidade <- round(matriz_confusao[1, 1] / sum(matriz_confusao[1,]),3)
npv <- round(matriz_confusao[2, 2] / sum(matriz_confusao[2, ]),3)
esp <- round(matriz_confusao[2, 2] / sum(matriz_confusao[ ,2]),3)
print(" ")
print(paste("A precisão do modelo e:", precisao))
print(paste("A sensibilidade do modelo e:", sensibilidade))
print(paste("o NPV do modelo e:", npv))
print(paste("A especificidade do modelo e:", esp))
print(paste("A acurácia do modelo e:", acuracia))
